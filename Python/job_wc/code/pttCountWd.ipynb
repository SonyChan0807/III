{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"將PTT目標版面的文章、關鍵字標題、希望爬取頁數,將網址download至'pttFile.csv'檔案中\"\"\"\n",
    "\n",
    "def pttURL_crawler(board,keyWd,pageNo,writeFile):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import csv\n",
    "\n",
    "    \"\"\"擷取ptt文章列表的網頁,擷取每篇文章的連結\n",
    "       並翻每一頁網頁,爬取想要的頁數\"\"\"\n",
    "\n",
    "    URL = \"https://www.ptt.cc/\"\n",
    "    headers = {\"cookies\" : \"over18=1\"}\n",
    "    #希望爬取ptt板面、但是頁面擷取的網址內容會缺乏URL,需要自行補上\n",
    "    res = requests.get(URL + \"bbs/\" + board +\"/index.html\" , headers = headers)\n",
    "    soup = BeautifulSoup(res.text , 'lxml')\n",
    "\n",
    "    bottons = soup.select('a.btn.wide')\n",
    "    #totalpage=上一頁的頁數+1\n",
    "    totalpage = int(bottons[1]['href'].split('index')[1].split('.')[0])+1\n",
    "\n",
    "    \"\"\"在希望的頁數（totalpage ~ crawlpage-n)的文章列表中,希望爬出文章標題為\"KeyWord\"的網址\n",
    "       所以,只要爬到該文章就將網址寫入'pttFile.csv'\n",
    "    \"\"\"\n",
    "    \n",
    "    for page in range(totalpage,totalpage - pageNo, -1):\n",
    "    \n",
    "        res = requests.get(URL+ \"bbs/\" + board +\"/index{}.html\".format(page),headers = headers)    \n",
    "        soup = BeautifulSoup(res.text,'lxml')\n",
    "        links = soup.select('div.title > a')\n",
    "        \n",
    "        #爬取該頁面中每一篇有'keyword'的文章\n",
    "        for link in links:\n",
    "            title = link.text\n",
    "            if(keyWd) in title:        \n",
    "                article_URL = URL +link['href']\n",
    "                print(article_URL) \n",
    "                #只要爬到該keyword的文章寫入'pttFile.csv'\n",
    "                with open(writeFile,'a') as fw:\n",
    "                    fw.write(article_URL + '\\n')\n",
    "    \n",
    "    return print(\"download finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"將csv檔案中的網址（ptt）內容爬出（限定只有英文的部份）並寫入檔案中\"\"\"\n",
    "\n",
    "def pttEng_crawler(readFile,writeFile):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import csv\n",
    "    import re\n",
    "\n",
    "    \"\"\"#將檔案中的網址讀取,並進入該網址（ptt）的頁面\"\"\"\n",
    "    with open(readFile,'r') as fr:\n",
    "        for URL in fr:\n",
    "            article_URL = URL.strip()        \n",
    "            res   = requests.get(article_URL,headers = {\"cookies\" : \"over18=1\"})\n",
    "            soup  = BeautifulSoup(res.text,\"lxml\") \n",
    "            links = soup.select(\"div.article-metaline > span\")\n",
    "            \n",
    "            #預期將所有文章的英文串接\n",
    "            \"\"\"將每篇文章的內容爬出,並過濾爬出只有英文字的內容,每篇文章的英文字會以'*'串接,並寫入檔案中\"\"\"\n",
    "            for link in links:\n",
    "\n",
    "                words = []    \n",
    "                article_dict ={}   \n",
    "                #去除文章本文以外的標籤    \n",
    "                trash_link = soup.select('div.article-metaline > span') + soup.select('div.article-metaline-right > span') + soup.select('div.push') + soup.select('div#article-polling') \n",
    "                for trash in trash_link:\n",
    "                    trash.decompose()\n",
    "                #過濾文章內文,並將有英文的部份全部改為小寫    \n",
    "                content = soup.select_one(\"#main-container\")\n",
    "                for script in content.find_all('script'):\n",
    "                    script.decompose()\n",
    "                for a in content.select('a'):\n",
    "                    a.decompose()\n",
    "                article_dict['content'] =content.text\n",
    "                content = article_dict['content'].lower()\n",
    "                #過濾文章內容的特殊符號\n",
    "\n",
    "                clearContent = content.replace('\\n', '').replace('(', '').replace(')', '').replace(',', '').replace('.','')\n",
    "                #限定文章中只有英文是我們想要的內容\n",
    "                word = list(set(re.findall('object c|visual basic|[A-Za-z.+#]+',clearContent, re.IGNORECASE)))\n",
    "                #該篇文章所有的英文字串接為words\n",
    "    #                 print(word)\n",
    "                words += word\n",
    "\n",
    "            with open(writeFile,'a') as fw:\n",
    "                fw.write('*'.join(words) + '\\n')\n",
    "                \n",
    "    return print(\"get the English part of these article!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"將想要比較（本文文章）和被比較的檔案（有keyWord的斷詞）,相互比較得到keyWord出現的次數\"\"\"\n",
    "\n",
    "def CountKeyWd(compareFile,comparedFile,result):\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    #open 被比較的檔案（含有keyWord的斷詞）\n",
    "    with open(comparedFile,'r') as f:\n",
    "        lan = [text.lower() for text in f.read().split('\\n')]\n",
    "    #open 想要比較的本文檔案  \n",
    "    with open(compareFile,'r') as fr:        \n",
    "        wc = Counter()\n",
    "        \"\"\"只要本文檔案,每讀取一行（words)就經過處理成為好幾個word,\n",
    "        並判斷該word是否有在被比較檔案中（含有keyWord斷詞）,\n",
    "        如果有就value+1,反之就value為1\"\"\"\n",
    "        for strWd in fr:\n",
    "            words  = strWd.strip().split('*')       \n",
    "            \n",
    "            for word in words:\n",
    "                if word in lan:\n",
    "                    if word in wc:\n",
    "                        wc[word] += 1\n",
    "                    else: \n",
    "                        wc[word] = 1        \n",
    "    \"\"\"計算出各關鍵字出現數量就將檔案寫入'result'csv檔案中\"\"\"\n",
    "    with open(result, \"w\") as fw:\n",
    "        for k,v in  wc.most_common():\n",
    "            fw.write('{},{}'.format(k,v)  + '\\n')\n",
    "    return print(wc.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the English part of these article!\n",
      "[('javascript', 713), ('html', 677), ('java', 670), ('php', 650), ('android', 536), ('c', 530), ('linux', 516), ('mysql', 470), ('jquery', 466), ('ios', 439), ('c++', 404), ('c#', 282), ('python', 278), ('ajax', 272), ('ruby', 164), ('project', 140), ('oracle', 121), ('unix', 115), ('xml', 102), ('flash', 102), ('jsp', 93), ('http', 91), ('spring', 81), ('r', 75), ('asp', 69), ('perl', 67), ('shell', 63), ('illustrator', 62), ('excel', 57), ('postgresql', 55), ('oop', 54), ('socket', 49), ('swift', 46), ('apple', 45), ('security', 43), ('arm', 43), ('struts', 43), ('actionscript', 42), ('uml', 37), ('base', 37), ('matlab', 36), ('access', 33), ('word', 32), ('dhtml', 30), ('udp', 29), ('flex', 28), ('ideas', 27), ('tomcat', 27), ('dreamweaver', 27), ('firmware', 25), ('rdbms', 25), ('xhtml', 24), ('dns', 23), ('iis', 21), ('mfc', 20), ('firewall', 19), ('voip', 18), ('san', 18), ('assembly', 18), ('vmware', 17), ('dsp', 16), ('jsf', 16), ('soap', 16), ('bluetooth', 15), ('etl', 15), ('vpn', 15), ('ftp', 14), ('freebsd', 14), ('sap', 14), ('vba', 14), ('outlook', 13), ('cvs', 13), ('progress', 12), ('directx', 12), ('ssh', 11), ('mcu', 11), ('powerpoint', 11), ('drivers', 10), ('ooad', 10), ('delphi', 10), ('silverlight', 10), ('sdlc', 9), ('stl', 9), ('weblogic', 9), ('junit', 9), ('websphere', 9), ('ldap', 8), ('wan', 8), ('vbscript', 8), ('gis', 8), ('mes', 8), ('director', 7), ('winform', 7), ('bugzilla', 7), ('cisco', 7), ('cgi', 6), ('visio', 6), ('iptables', 6), ('rtsp', 6), ('routers', 6), ('activex', 6), ('cam', 6), ('snmp', 5), ('dos', 5), ('mantis', 5), ('fireworks', 5), ('plc', 5), ('lan', 5), ('loadrunner', 5), ('coreldraw', 5), ('photoimpact', 5), ('tcl', 4), ('sniffer', 4), ('ejb', 4), ('jms', 4), ('dhcp', 4), ('cim', 4), ('visual basic', 4), ('ado', 4), ('arcgis', 4), ('informix', 4), ('sybase', 3), ('odbc', 3), ('solaris', 3), ('sas', 3), ('servlets', 3), ('vms', 3), ('eda', 3), ('jdbc', 3), ('qtp', 3), ('frontpage', 3), ('ethernet', 2), ('fpga', 2), ('vlan', 2), ('edi', 2), ('asic', 2), ('labview', 2), ('biztalk', 2), ('powerbuilder', 2), ('maya', 2), ('aix', 2), ('rf', 2), ('ims', 2), ('wlan', 2), ('premiere', 2), ('autocad', 2), ('ddk', 2), ('vxworks', 1), ('verilog', 1), ('dbase', 1), ('hubs', 1), ('', 1), ('solidworks', 1), ('vrml', 1), ('xsl', 1)]\n"
     ]
    }
   ],
   "source": [
    "pttEng_crawler(\"softURL.csv\",\"softEng.csv\")\n",
    "CountKeyWd('softEng.csv','lan.csv','newSoftCount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the English part of these article!\n",
      "[('c', 235), ('c++', 193), ('linux', 188), ('android', 179), ('java', 178), ('ios', 125), ('html', 121), ('javascript', 118), ('php', 115), ('c#', 90), ('python', 89), ('project', 88), ('mysql', 82), ('jquery', 72), ('ruby', 60), ('r', 49), ('matlab', 41), ('unix', 40), ('word', 38), ('excel', 37), ('ajax', 33), ('security', 30), ('oracle', 26), ('perl', 25), ('http', 24), ('fpga', 24), ('base', 22), ('shell', 22), ('vmware', 21), ('rf', 20), ('illustrator', 19), ('verilog', 18), ('drivers', 18), ('xml', 18), ('flash', 17), ('arm', 15), ('powerpoint', 15), ('spring', 15), ('dsp', 15), ('access', 14), ('dns', 14), ('labview', 14), ('mcu', 13), ('eda', 12), ('firmware', 11), ('autocad', 11), ('wan', 11), ('swift', 10), ('iis', 10), ('udp', 10), ('ideas', 10), ('bluetooth', 9), ('solidworks', 9), ('sap', 9), ('apple', 8), ('xhtml', 8), ('uml', 8), ('plc', 8), ('vpn', 8), ('firewall', 7), ('san', 7), ('rdbms', 7), ('mes', 7), ('socket', 7), ('director', 6), ('sas', 6), ('cisco', 6), ('oop', 6), ('actionscript', 6), ('lan', 6), ('cim', 6), ('dreamweaver', 6), ('freebsd', 6), ('etl', 5), ('assembly', 5), ('jsp', 5), ('routers', 5), ('dhcp', 5), ('snmp', 5), ('asp', 5), ('dhtml', 5), ('struts', 5), ('outlook', 5), ('progress', 4), ('orcad', 4), ('mfc', 4), ('coreldraw', 4), ('frontpage', 4), ('photoimpact', 4), ('ssh', 3), ('stl', 3), ('ethernet', 3), ('servlets', 3), ('cam', 3), ('catia', 3), ('winform', 3), ('protel', 3), ('postgresql', 3), ('', 3), ('rtsp', 2), ('maya', 2), ('vba', 2), ('ldap', 2), ('voip', 2), ('flex', 2), ('cvs', 2), ('visual basic', 2), ('directx', 2), ('ftp', 2), ('tomcat', 2), ('websphere', 2), ('bugzilla', 2), ('loadrunner', 2), ('dos', 1), ('tcl', 1), ('sybase', 1), ('cgi', 1), ('iptables', 1), ('vxworks', 1), ('vlan', 1), ('visio', 1), ('vbscript', 1), ('junit', 1), ('delphi', 1), ('wlan', 1), ('soap', 1), ('ooad', 1), ('asic', 1), ('jdbc', 1), ('odbc', 1), ('premiere', 1), ('vms', 1), ('sdlc', 1), ('abaqus', 1), ('smt', 1), ('weblogic', 1)]\n"
     ]
    }
   ],
   "source": [
    "pttEng_crawler(\"techURL.csv\",\"techEng.csv\")\n",
    "CountKeyWd('techEng.csv','lan.csv','newTechCount.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}